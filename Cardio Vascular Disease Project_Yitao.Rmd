---
title: "Cardio Vascular Disease Project"
author: "Team 1: Afif Mahmassani, Turner Luo, Lijia Ren, Steven Tian"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=F}
library(ezids)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
```
# Introudction

# Description of Dataset  
```{r}
cardio_vascular_disease <- read.csv2("cardio_train.csv", header = TRUE)
str(cardio_vascular_disease)
```
Noticed some of the variables should be factor.    
```{r}
df <- cardio_vascular_disease
df$id <- NULL
df$gender <- factor(cardio_vascular_disease$gender)
df$smoke <- factor(cardio_vascular_disease$smoke)
df$alco <- factor(cardio_vascular_disease$alco)
df$active <- factor(cardio_vascular_disease$active)
df$cardio <- factor(cardio_vascular_disease$cardio)
df$cholesterol <- factor(cardio_vascular_disease$cholesterol)
df$gluc <- factor(cardio_vascular_disease$gluc)
df$weight <- as.integer(cardio_vascular_disease$weight)

levels(df$cardio) <- c("No", "Yes")
levels(df$gender) <- c("Female", "Male")
levels(df$cholesterol) <- c("Normal", "Above Normal", "Well Above Normal")
levels(df$gluc) <- c("Normal", "Above Normal", "Well Above Normal")
levels(df$smoke) <- c("No", "Yes")
levels(df$alco) <- c("No", "Yes")
levels(df$active) <- c("No", "Yes")
df <- na.omit(df)

str(df)
``` 
The variables in the dataset are:   

* `id`: Patient ID   
* `age`: Age (in days)
* `gender`: Gender, 1: Female, 2: Male
* `height`: Height (in cm)
* `weight`: Weight (in kg)
* `ap_hi`: Systolic blood pressure
* `ap_lo`: Diastolic blood pressure
* `cholesterol`: Cholesterol, 1: Normal, 2: Above Normal, 3: Well Above Normal
* `glue`: Glucose, 1: Normal, 2: Above Normal, 3: Well Above Normal
* `smoke`: Whether patient smokes or not, 1: Do not smoke, 2: Smoke
* `alco`: Alcohol intake, 1: Do not drink alcohol, 2: Drink alcohol
* `active`: Physical activity, 1: Do not exercise, 2: Exercise
* `df`: Presence or absence of cardiovascular disease, 1: Absence, 2: Presence


```{r}
xkablesummary(df[,2:12], title = "Summary of Cardio Vascular Disease Data")
```
# Categorical Variables EDA   
# Continuous Variables EDA     
# EDA on the joint effect of influencing factors     
# Model Comparison      
## Logistic Regression   
```{r}
#need correlation plot to select variables
df_num <- df
for(i in 1:12){
  if (!(i %in% c(1,3:6))){
    df_num[,i] = as.numeric(df_num[,i])
  }
}
str(df_num)
cor <- cor(df_num, method = "spearman")
loadPkg("corrplot")
corrplot(cor, type="lower", addCoef.col="black", number.cex=0.5, tl.cex=0.7,title="Cardio Vascular Disease Correlation", mar=c(0,0,1,0))
```
### Coefficient:     
The first model we are performing is logistic regression model. There are 13 variables, first we exclude `id` which is not related to the cardio vascular disease. Then to prevent the multicollinearity, we choose one between `ap_hi` and `ap_lo`. So, we start with a logistic model with 10 variables. We set alpha equal to 0.05, so we should exclude all the variable that have p-value larger than 0.05.   
```{r}
logistic_all <- glm(cardio ~ age + gender + height + weight + ap_hi + ap_lo + cholesterol + gluc + smoke + alco + active, data = df, family = "binomial")
summary(logistic_all)
```
With p-value of 0.49, we delete `gender`.  
```{r}
logistic_1 <- glm(cardio ~ age + height + weight + ap_hi + ap_lo + cholesterol + gluc + smoke + alco + active, data = df, family = "binomial")
summary(logistic_1)
```
Delete `gluc`.    
```{r}
logistic_2 <- glm(cardio ~ age + height + weight + ap_hi + ap_lo + cholesterol + smoke + alco + active, data = df, family = "binomial")
summary(logistic_2)
```
### Confusion Matrix:  
```{r, results='markup'}
loadPkg("regclass")
confusion_matrix(logistic_2)
xkabledply( confusion_matrix(logistic_2), title = "Confusion matrix from Logit Model" )
cfmatrix1 = confusion_matrix(logistic_2)
accuracy1 <- (cfmatrix1[1,1]+cfmatrix1[2,2])/cfmatrix1[3,3]
precision1 <- cfmatrix1[2,2]/(cfmatrix1[2,2]+cfmatrix1[1,2])
recall1 <- cfmatrix1[2,2]/(cfmatrix1[2,2]+cfmatrix1[2,1])
specificity1 <- cfmatrix1[1,1]/(cfmatrix1[1,1]+cfmatrix1[1,2])
F1_score1 <- 2*(precision1)*(recall1)/(precision1 + recall1)
accuracy1
precision1
recall1
specificity1
F1_score1
```
### AUC and ROC:   
```{r, results='markup'}
loadPkg("pROC")
prob <- predict(logistic_2, type = "response")
df$prob <- prob
h <- roc(cardio ~ prob, data = df)
auc(h)
plot(h)
```
### McFadden:   
```{r,results='markup'}
loadPkg("pscl")
Logitpr2 = pR2(logistic_2)
Logitpr2
```
## KNN    
### Center and Scale   
```{r}
#convert variables to numeric
str(df_num)
scale1 <- subset(df_num, select = -c(cardio, prob))
scale1$cardio <- df$cardio
str(scale1)
scale1[c(1,3,4,5,6)] <- as.data.frame(scale(scale1[c(1,3,4,5,6)], center = TRUE, scale = TRUE))
set.seed(1)
df_sample <- sample(2, nrow(scale1), replace = TRUE, prob = c(0.75,0.25))
df_train <- scale1[df_sample==1, 1:11]
df_test <- scale1[df_sample==2, 1:11]
df.trainLabels <- df[df_sample==1, 12]
df.testLabels <- df[df_sample==2, 12]

```
### Select K
```{r, echo=FALSE}
loadPkg("class")
chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k) #,                #<- number of neighbors considered
                  # use.all = TRUE)       #<- control ties between class assignments. If true, all distances equal to the k-th largest are included
  
  tab = table(class_knn, val_class)
  #cm = confusionMatrix(class_knn, reference = cus_test_y ) # from caret library
  # print.confusionMatrix(cm)
  # 
  #cmaccu = cm$overall['Accuracy']
  
  # Calculate the accuracy.
  accu = sum(tab[row(tab) == col(tab)]) / sum(tab)                         
  cbind(k = k, accuracy = accu)
}
```
```{r, results='markup'}
knn_different_k = sapply(seq(1, 21, by = 2),  
                         function(x) chooseK(x, 
                                             train_set = df_train,
                                             val_set = df_test,
                                             train_class = df.trainLabels,
                                             val_class = df.testLabels))
knn_different_k = data.frame(k = knn_different_k[1,],
                             accuracy = knn_different_k[2,])
library("ggplot2")
ggplot(knn_different_k,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3) + 
  labs(title = "accuracy vs k")
xkabledply((knn_different_k))
```
It seems that `k=17` should be our best selection here.

### Evalution   
```{r, results='markup'}
pred <- knn(train = df_train, test = df_test, cl=df.trainLabels, k=17)
pred

loadPkg("gmodels")
churnPredCross <- CrossTable(df.testLabels, pred, prop.chisq = FALSE)
```
### KNN with selected variables    
Remove `gender` and `gluc`.   
```{r}
df_num2 <- subset(df_num, select = -c(gender, gluc, prob))
str(df_num2)
scale2 <- df_num2
scale2[1:5] <- scale(df_num2[1:5], center = TRUE, scale = TRUE)
scale2$cardio <- df$cardio
str(scale2)
```
```{r}
set.seed(1)
df_sample2 <- sample(2, nrow(scale2), replace = TRUE, prob = c(0.75,0.25))
df_train2 <- scale2[df_sample2==1, 1:9]
df_test2 <- scale2[df_sample2==2, 1:9]
df.trainLabel2 <- scale2[df_sample2==1, 10]
df.testLabel2 <- scale2[df_sample2==2, 10]
```
### Select K    
```{r, results='markup'}
knn_different_k2 = sapply(seq(1, 21, by = 2),  
                         function(x) chooseK(x, 
                                             train_set = df_train2,
                                             val_set = df_test2,
                                             train_class = df.trainLabel2,
                                             val_class = df.testLabel2))
str(knn_different_k2)
knn_different_k2 = data.frame(k = knn_different_k2[1,],
                             accuracy = knn_different_k2[2,])
library("ggplot2")
ggplot(knn_different_k2,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3) + 
  labs(title = "accuracy vs k")
xkabledply((knn_different_k2))
```
We should better select value `k=13` here as it has the highest accuracy.   
```{r}
pred2 <- knn(train = df_train2, test = df_test2, cl = df.trainLabel2, k = 13)
knn.roc.prob <- attr(knn(train = df_train2, test = df_test2, cl = df.trainLabel2, k = 13, prob = T), 'prob')
pred2
```
### Evalution   
```{r, results='markup'}
churnPredCross2 <- CrossTable(df.testLabel2, pred2, prop.chisq = FALSE)
```
### Comparison  
## Classifiction Tree    
```{r, results='markup'}
str(df_num)
library(randomForest)
fit_im <- randomForest(df_num$cardio ~., data = df_num)
```
```{r}
importance(fit_im)
varImpPlot(fit_im)
```
Choose top 6 features to build the tree model: `ap_hi`, `age`, `weight`, `ap_lo`, `height`, `cholesterol`.    
```{r}
loadPkg("rpart")
loadPkg("caret")



# create an empty dataframe to store the results from confusion matrices
confusionMatrixResultDf = data.frame(Depth = numeric(0), Accuracy  = numeric(0), Sensitivity = numeric(0), Specificity = numeric(0), 
                                      Pos.Pred.Value = numeric(0), Neg.Pred.Value = numeric(0), Precision = numeric(0), Recall = numeric(0),
                                      F1 = numeric(0), Prevalence = numeric(0), Detection.Rate = numeric(0), Detection.Prevalence = numeric(0),
                                      Balanced.Accurary = numeric(0), row.names = NULL)

for (deep in 2:6) {
  kfit <- rpart(cardio ~ ap_hi + age + weight + ap_lo + height + cholesterol, data = df_num, method="class", control = list(maxdepth = deep) )
  # 
  cm = confusionMatrix( predict(kfit, type = "class"), reference = df_num[, "cardio"] ) # from caret library
  # 
  cmaccu = cm$overall['Accuracy']
  # print( paste("Total Accuracy = ", cmaccu ) )
  # 
  cmt = data.frame(Depth=deep, Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
  confusionMatrixResultDf = rbind(confusionMatrixResultDf, cmt)
  # print("Other metrics : ")
}

unloadPkg("caret")
```
```{r}
xkabledply(ConfusionMatrixResultDF, title = "Cardio Classificantion Trees summary with varying MaxDepth")
```
```{r}
set.seed(1000)
cardiofit <- rpart(cardio ~ ap_hi + age + weight + ap_lo + height + cholesterol, data = df_num, method = "class", control = list(maxdepth=6))
printcp(cardiofit)
plotcp(cardiofit)
summary(cardiofit)
```
```{r}
plot(cardiofit, uniform = TRUE, main = "Classification Tree for Cardio")
text(cardiofit, use.n = TRUE, all = TRUE, cex = 1)
```









